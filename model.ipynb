{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "bacf2cb3",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import pandas as pd\nimport ast\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable"
        },
        {
            "cell_type": "markdown",
            "id": "a3c28aa9",
            "metadata": {},
            "source": "### Load Data"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "f9592938",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "class RedDataset(Dataset):\n    def __init__(self, datafile, train):\n        self.data = pd.read_csv(datafile)\n        self.data = self.data[self.data['train'] == train]\n        self.data = self.data.reset_index(drop=True)\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, idx):\n        item = self.data.loc[idx]\n        return torch.tensor(ast.literal_eval(item['data'])), torch.tensor(item['label'])\n\n    def shape(self):\n        item = self.data.loc[0]\n        lst = ast.literal_eval(item['data'])\n        return len(lst), len(lst[0])"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "90cf2e00",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "60000\n10000\n"
                }
            ],
            "source": "filename = 'RedData/RedData_24i.csv'\ntrain_data = RedDataset(filename, train=True)\nprint(len(train_data))\ntest_data = RedDataset(filename, train=False)\nprint(len(test_data))\n\nloaders = {\n    'train': DataLoader(train_data,\n                        batch_size=100,\n                        shuffle=True,\n                        num_workers=1),\n\n    'test': DataLoader(test_data,\n                       batch_size=100,\n                       shuffle=True,\n                       num_workers=1),\n}"
        },
        {
            "cell_type": "markdown",
            "id": "f5fb4e2e",
            "metadata": {},
            "source": "### Model architecture"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "6c5f42ff",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "class RedModel(nn.Module):\n    def __init__(self, input_size):\n        super(RedModel, self).__init__()\n        layer_size = input_size[0] * input_size[1]\n        self.linear1 = nn.Linear(layer_size, layer_size)\n        self.relu1 = nn.ReLU()\n        self.out = nn.Linear(layer_size, 10)\n\n    def forward(self, x):\n        x1 = x.view(x.size(0), -1)\n        x2 = self.linear1(x1)\n        x3 = self.relu1(x2)\n        output = self.out(x3)\n        return {\n            'in': x,\n            'out': output,\n            'trans': x1,\n            'linear1': x2,\n            'relu1': x3,\n        }"
        },
        {
            "cell_type": "markdown",
            "id": "b653b996",
            "metadata": {},
            "source": "### Train model"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "5b9af8da",
            "metadata": {
                "scrolled": true,
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Device: cpu\nEpoch [1/10], Step [100/600], Loss: 1.6823\nEpoch [1/10], Step [200/600], Loss: 1.4081\nEpoch [1/10], Step [300/600], Loss: 1.4602\nEpoch [1/10], Step [400/600], Loss: 1.4940\nEpoch [1/10], Step [500/600], Loss: 1.5102\nEpoch [1/10], Step [600/600], Loss: 1.4425\nEpoch [2/10], Step [100/600], Loss: 1.4979\nEpoch [2/10], Step [200/600], Loss: 1.4122\nEpoch [2/10], Step [300/600], Loss: 1.3252\nEpoch [2/10], Step [400/600], Loss: 1.8645\nEpoch [2/10], Step [500/600], Loss: 1.4200\nEpoch [2/10], Step [600/600], Loss: 1.2900\nEpoch [3/10], Step [100/600], Loss: 1.3773\nEpoch [3/10], Step [200/600], Loss: 1.5749\nEpoch [3/10], Step [300/600], Loss: 1.2898\nEpoch [3/10], Step [400/600], Loss: 1.3249\nEpoch [3/10], Step [500/600], Loss: 1.5266\nEpoch [3/10], Step [600/600], Loss: 1.3592\nEpoch [4/10], Step [100/600], Loss: 1.1953\nEpoch [4/10], Step [200/600], Loss: 1.2373\nEpoch [4/10], Step [300/600], Loss: 1.4674\nEpoch [4/10], Step [400/600], Loss: 1.3409\nEpoch [4/10], Step [500/600], Loss: 1.2824\nEpoch [4/10], Step [600/600], Loss: 1.2748\nEpoch [5/10], Step [100/600], Loss: 1.4389\nEpoch [5/10], Step [200/600], Loss: 1.5253\nEpoch [5/10], Step [300/600], Loss: 1.5801\nEpoch [5/10], Step [400/600], Loss: 1.3443\nEpoch [5/10], Step [500/600], Loss: 1.4288\nEpoch [5/10], Step [600/600], Loss: 1.4178\nEpoch [6/10], Step [100/600], Loss: 1.2304\nEpoch [6/10], Step [200/600], Loss: 1.3950\nEpoch [6/10], Step [300/600], Loss: 1.2856\nEpoch [6/10], Step [400/600], Loss: 1.3623\nEpoch [6/10], Step [500/600], Loss: 1.2211\nEpoch [6/10], Step [600/600], Loss: 1.3658\nEpoch [7/10], Step [100/600], Loss: 1.2175\nEpoch [7/10], Step [200/600], Loss: 1.1163\nEpoch [7/10], Step [300/600], Loss: 1.5198\nEpoch [7/10], Step [400/600], Loss: 1.2682\nEpoch [7/10], Step [500/600], Loss: 1.3537\nEpoch [7/10], Step [600/600], Loss: 1.2805\nEpoch [8/10], Step [100/600], Loss: 1.3451\nEpoch [8/10], Step [200/600], Loss: 1.3495\nEpoch [8/10], Step [300/600], Loss: 1.2726\nEpoch [8/10], Step [400/600], Loss: 1.1753\nEpoch [8/10], Step [500/600], Loss: 1.2056\nEpoch [8/10], Step [600/600], Loss: 1.4644\nEpoch [9/10], Step [100/600], Loss: 1.2436\nEpoch [9/10], Step [200/600], Loss: 1.2861\nEpoch [9/10], Step [300/600], Loss: 1.3147\nEpoch [9/10], Step [400/600], Loss: 1.3217\nEpoch [9/10], Step [500/600], Loss: 1.2135\nEpoch [9/10], Step [600/600], Loss: 1.3119\nEpoch [10/10], Step [100/600], Loss: 1.2996\nEpoch [10/10], Step [200/600], Loss: 1.4282\nEpoch [10/10], Step [300/600], Loss: 1.3881\nEpoch [10/10], Step [400/600], Loss: 1.2824\nEpoch [10/10], Step [500/600], Loss: 1.3232\nEpoch [10/10], Step [600/600], Loss: 1.4004\n"
                }
            ],
            "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Device: {device}')\n\nmodel = RedModel(train_data.shape())\nloss_func = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nnum_epochs = 10\n\n\ndef train(num_epochs, model, loaders):\n\n    model.train()\n\n    # Train the model\n    total_step = len(loaders['train'])\n\n    for epoch in range(num_epochs):\n        for i, (images, labels) in enumerate(loaders['train']):\n\n            # gives batch data, normalize x when iterate train_loader\n            b_x = Variable(images)   # batch x\n            b_y = Variable(labels)   # batch output = model(b_x)[0]\n\n            results = model(b_x)['out']\n            loss = loss_func(results, b_y)\n\n            # clear gradients for this training step\n            optimizer.zero_grad()\n\n            # backpropagation, compute gradients\n            loss.backward()                # apply gradients\n            optimizer.step()\n\n            if (i + 1) % 100 == 0:\n                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n                pass\n\n        pass\n\n    pass\n\n\ntrain(num_epochs, model, loaders)"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "9478743b",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Test Accuracy of the model on the 10000 test images: 0.55\n"
                }
            ],
            "source": "def test():\n    model.eval()\n    with torch.no_grad():\n        for images, labels in loaders['test']:\n            results = model(images)\n            pred_y = torch.max(results['out'], 1)[1].data.squeeze()\n            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n            pass\n\n    print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n    pass\n\n\ntest()\n\ntorch.save(model.state_dict(), 'model.pt')"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "toc": {
            "base_numbering": 1,
            "nav_menu": {},
            "number_sections": true,
            "sideBar": true,
            "skip_h1_title": false,
            "title_cell": "Table of Contents",
            "title_sidebar": "Contents",
            "toc_cell": false,
            "toc_position": {},
            "toc_section_display": true,
            "toc_window_display": false
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}