{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "a6153b22",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import pandas as pd\nimport ast\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable"
        },
        {
            "cell_type": "markdown",
            "id": "eba007cb",
            "metadata": {},
            "source": "### Load Data"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "c8c9bf65",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "                                                   data  label  train\n0     [[ 0.48066562, 0.00831655,-0.39940253,-0.35378...      6  False\n1     [[ 0.37403064, 0.77835609, 0.66822243, 0.21494...      3  False\n2     [[-0.39066542,-0.23299751, 0.30417249, 0.34154...      1  False\n3     [[-0.33413517,-0.26792407,-0.10983959, 0.02827...      9  False\n4     [[-0.42956538,-0.59341336,-0.01145271, 0.47951...      4  False\n...                                                 ...    ...    ...\n9995  [[ 0.19634359, 0.67472106, 0.71291648, 0.24256...      1  False\n9996  [[-0.09088958,-0.22722709,-0.24110945, 0.03927...      7  False\n9997  [[-0.31489196, 0.16063953, 0.63439211, 0.76918...      9  False\n9998  [[ 0.26800376, 0.13536895, 0.30791984, 0.55271...      9  False\n9999  [[ 0.35186673, 0.25961248, 0.18172967, 0.11000...      6  False\n\n[10000 rows x 3 columns]\n(tensor([[ 0.4807,  0.0083, -0.3994, -0.3538],\n        [ 0.4291, -0.4309, -0.6659, -0.5255],\n        [ 0.3449, -0.2069, -0.0395,  0.0740],\n        [ 0.3411,  0.1778,  0.5453,  0.6857]]), tensor(6))\n(tensor([[-0.3176, -0.2218,  0.1340,  0.4381],\n        [-0.6159, -0.1518,  0.2497,  0.2415],\n        [-0.2511,  0.4885,  0.6465,  0.3941],\n        [ 0.5188,  0.9961,  0.6616,  0.3150]]), tensor(1))\n"
                }
            ],
            "source": "class RedDataset(Dataset):\n    def __init__(self, datafile, train):\n        self.data = pd.read_csv(datafile)\n        self.data = self.data[self.data['train'] == train]\n        self.data = self.data.reset_index(drop=True)\n        \n        print(self.data)\n        \n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, idx):\n        item = self.data.loc[idx]\n        return torch.tensor(ast.literal_eval(item['data'])), torch.tensor(item['label'])\n\n    def shape(self):\n        item = self.data.loc[0]\n        lst = ast.literal_eval(item['data'])\n        return len(lst), len(lst[0])\n\ntest_data = RedDataset('RedData.csv', train=False)\n\nprint(test_data[0])\nprint(train_data[0])"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "d8fc2cb9",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "60000\n10000\n"
                }
            ],
            "source": "train_data = RedDataset('RedData.csv', train=True)\nprint(len(train_data))\ntest_data = RedDataset('RedData.csv', train=False)\nprint(len(test_data))\n\nloaders = {\n    'train': DataLoader(train_data,\n                        batch_size=100,\n                        shuffle=True,\n                        num_workers=1),\n\n    'test': DataLoader(test_data,\n                       batch_size=100,\n                       shuffle=True,\n                       num_workers=1),\n}"
        },
        {
            "cell_type": "markdown",
            "id": "bea426ea",
            "metadata": {},
            "source": "### Model architecture"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "31dbb988",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "class RedModel(nn.Module):\n    def __init__(self, input_size):\n        super(RedModel, self).__init__()\n        layer_size = input_size[0] * input_size[1]\n        self.linear1 = nn.Linear(layer_size, layer_size)\n        self.relu1 = nn.ReLU()\n        self.out = nn.Linear(layer_size, 10)\n\n    def forward(self, x):\n        x1 = x.view(x.size(0), -1)\n        x2 = self.linear1(x1)\n        x3 = self.relu1(x2)\n        output = self.out(x3)\n        return {\n            'in': x,\n            'out': output,\n            'trans': x1,\n            'linear1': x2,\n            'relu1': x3,\n        }"
        },
        {
            "cell_type": "markdown",
            "id": "caadd946",
            "metadata": {},
            "source": "### Train model"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "79427b31",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Device: cpu\nEpoch [1/10], Step [100/600], Loss: 1.5895\nEpoch [1/10], Step [200/600], Loss: 1.7488\nEpoch [1/10], Step [300/600], Loss: 1.5267\nEpoch [1/10], Step [400/600], Loss: 1.4877\nEpoch [1/10], Step [500/600], Loss: 1.3739\nEpoch [1/10], Step [600/600], Loss: 1.4713\nEpoch [2/10], Step [100/600], Loss: 1.5069\nEpoch [2/10], Step [200/600], Loss: 1.3611\nEpoch [2/10], Step [300/600], Loss: 1.2250\nEpoch [2/10], Step [400/600], Loss: 1.2422\nEpoch [2/10], Step [500/600], Loss: 1.2792\nEpoch [2/10], Step [600/600], Loss: 1.4943\nEpoch [3/10], Step [100/600], Loss: 1.5449\nEpoch [3/10], Step [200/600], Loss: 1.1930\nEpoch [3/10], Step [300/600], Loss: 1.4722\nEpoch [3/10], Step [400/600], Loss: 1.4463\nEpoch [3/10], Step [500/600], Loss: 1.2877\nEpoch [3/10], Step [600/600], Loss: 1.4179\nEpoch [4/10], Step [100/600], Loss: 1.5591\nEpoch [4/10], Step [200/600], Loss: 1.1574\nEpoch [4/10], Step [300/600], Loss: 1.1119\nEpoch [4/10], Step [400/600], Loss: 1.1926\nEpoch [4/10], Step [500/600], Loss: 1.3648\nEpoch [4/10], Step [600/600], Loss: 1.1506\nEpoch [5/10], Step [100/600], Loss: 1.2708\nEpoch [5/10], Step [200/600], Loss: 1.4105\nEpoch [5/10], Step [300/600], Loss: 1.3146\nEpoch [5/10], Step [400/600], Loss: 1.2180\nEpoch [5/10], Step [500/600], Loss: 1.1193\nEpoch [5/10], Step [600/600], Loss: 1.4827\nEpoch [6/10], Step [100/600], Loss: 1.1587\nEpoch [6/10], Step [200/600], Loss: 1.2364\nEpoch [6/10], Step [300/600], Loss: 1.2661\nEpoch [6/10], Step [400/600], Loss: 1.2099\nEpoch [6/10], Step [500/600], Loss: 1.1117\nEpoch [6/10], Step [600/600], Loss: 1.4058\nEpoch [7/10], Step [100/600], Loss: 1.4678\nEpoch [7/10], Step [200/600], Loss: 1.5659\nEpoch [7/10], Step [300/600], Loss: 1.2857\nEpoch [7/10], Step [400/600], Loss: 1.1496\nEpoch [7/10], Step [500/600], Loss: 1.3687\nEpoch [7/10], Step [600/600], Loss: 1.2073\nEpoch [8/10], Step [100/600], Loss: 1.1841\nEpoch [8/10], Step [200/600], Loss: 1.4068\nEpoch [8/10], Step [300/600], Loss: 1.2556\nEpoch [8/10], Step [400/600], Loss: 1.1043\nEpoch [8/10], Step [500/600], Loss: 1.3832\nEpoch [8/10], Step [600/600], Loss: 1.2045\nEpoch [9/10], Step [100/600], Loss: 1.2019\nEpoch [9/10], Step [200/600], Loss: 1.3148\nEpoch [9/10], Step [300/600], Loss: 1.0713\nEpoch [9/10], Step [400/600], Loss: 1.1979\nEpoch [9/10], Step [500/600], Loss: 1.2888\nEpoch [9/10], Step [600/600], Loss: 1.1793\nEpoch [10/10], Step [100/600], Loss: 1.2129\nEpoch [10/10], Step [200/600], Loss: 1.2554\nEpoch [10/10], Step [300/600], Loss: 1.0382\nEpoch [10/10], Step [400/600], Loss: 1.2879\nEpoch [10/10], Step [500/600], Loss: 1.2311\nEpoch [10/10], Step [600/600], Loss: 1.1797\n"
                }
            ],
            "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Device: {device}')\n\nmodel = RedModel(train_data.shape())\nloss_func = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nnum_epochs = 10\n\n\ndef train(num_epochs, model, loaders):\n\n    model.train()\n\n    # Train the model\n    total_step = len(loaders['train'])\n\n    for epoch in range(num_epochs):\n        for i, (images, labels) in enumerate(loaders['train']):\n\n            # gives batch data, normalize x when iterate train_loader\n            b_x = Variable(images)   # batch x\n            b_y = Variable(labels)   # batch output = model(b_x)[0]\n\n            results = model(b_x)['out']\n            loss = loss_func(results, b_y)\n\n            # clear gradients for this training step\n            optimizer.zero_grad()\n\n            # backpropagation, compute gradients\n            loss.backward()                # apply gradients\n            optimizer.step()\n\n            if (i + 1) % 100 == 0:\n                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n                pass\n\n        pass\n\n    pass\n\n\ntrain(num_epochs, model, loaders)"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "3144c5ab",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "ename": "KeyError",
                    "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 2606, in pandas._libs.hashtable.Int64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 2630, in pandas._libs.hashtable.Int64HashTable.get_item\nKeyError: 2412\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_14192/2465348463.py\", line 10, in __getitem__\n    item = self.data.loc[idx]\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1191, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1431, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1381, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/generic.py\", line 4301, in xs\n    loc = index.get_loc(key)\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 2412\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy of the model on the 10000 test images: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m accuracy)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
                        "Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m loaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      5\u001b[0m         results \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m      6\u001b[0m         pred_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msqueeze()\n",
                        "File \u001b[0;32m~/Code/cysec/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
                        "File \u001b[0;32m~/Code/cysec/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/Code/cysec/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
                        "File \u001b[0;32m~/Code/cysec/lib/python3.9/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
                        "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 2606, in pandas._libs.hashtable.Int64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 2630, in pandas._libs.hashtable.Int64HashTable.get_item\nKeyError: 2412\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_14192/2465348463.py\", line 10, in __getitem__\n    item = self.data.loc[idx]\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1191, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1431, in _getitem_axis\n    return self._get_label(key, axis=axis)\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1381, in _get_label\n    return self.obj.xs(label, axis=axis)\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/generic.py\", line 4301, in xs\n    loc = index.get_loc(key)\n  File \"/home/croniev/Code/cysec/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 2412\n"
                    ]
                }
            ],
            "source": "def test():\n    model.eval()\n    with torch.no_grad():\n        for images, labels in loaders['test']:\n            results = model(images)\n            pred_y = torch.max(results['out'], 1)[1].data.squeeze()\n            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n            pass\n\n    print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n    pass\n\n\ntest()\n\ntorch.save(model.state_dict(), 'model.pt')"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "toc": {
            "base_numbering": 1,
            "nav_menu": {},
            "number_sections": true,
            "sideBar": true,
            "skip_h1_title": false,
            "title_cell": "Table of Contents",
            "title_sidebar": "Contents",
            "toc_cell": false,
            "toc_position": {},
            "toc_section_display": true,
            "toc_window_display": false
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}