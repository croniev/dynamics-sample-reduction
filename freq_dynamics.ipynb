{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "ae24db26",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "from itertools import product\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n# from torch.nn.functional import relu\n# from torch.nn.functional import tanh\n# from torch.nn.functional import sigmoid\nfrom scipy.fftpack import dct\nfrom scipy.signal import convolve2d\nfrom skimage.measure import block_reduce\nfrom sklearn import svm"
        },
        {
            "cell_type": "markdown",
            "id": "ecb4e742",
            "metadata": {},
            "source": "## Reduce the data size by shrinking the image and allow symbolic dynamics to occur (based on doppler-effect)."
        },
        {
            "cell_type": "markdown",
            "id": "49c0b91c",
            "metadata": {},
            "source": "### Load the data"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "291310fd",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "train_data = datasets.MNIST(\n    root='data',\n    train=True,\n    transform=ToTensor(),\n    download=True,\n)\ntest_data = datasets.MNIST(\n    root='data',\n    train=False,\n    transform=ToTensor(),\n)\ndata_len = {'train': len(train_data), 'test': len(test_data)}\n\nloaders = {\n    'train': DataLoader(train_data,\n                        batch_size=100,\n                        shuffle=True,\n                        num_workers=1),\n\n    'test': DataLoader(test_data,\n                       batch_size=100,\n                       shuffle=True,\n                       num_workers=1),\n}"
        },
        {
            "cell_type": "markdown",
            "id": "b60872e9",
            "metadata": {},
            "source": "### Symbolic dynamics through iteration and non-linearity.\nThrough multiple iterations apply the doppler effect to the DCT of the images and apply convolution.  \nSave the results in a dataframe for easy loading."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "ac4a4652",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "def relu(x):\n    return np.maximum(0, x)\nrelu = np.vectorize(relu)\n# sigmoid = np.vectorize(lambda x: 1 / (1 + np.exp(-x)))\ntanh = np.vectorize(np.tanh)\n\ndef lrelu(x):\n    l_ = 0.025\n    return np.maximum(0, x) + l_ * np.minimum(0, x)\nlrelu = np.vectorize(lrelu)\n\ndef rrelu(x):\n    return np.maximum(0, x) + np.random.rand() / 10 * np.minimum(0, x)\nrrelu = np.vectorize(rrelu)\n\ndef elu(x):\n    l_ = 0.05\n    return np.maximum(0, x) + np.minimum(l_ * np.expm1(x), 0)\nelu = np.vectorize(elu)"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "78d239c4",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "def apply_dynamics(sample, iters, f_act, vel, v_o, v_m, kernel, conv=False, pool=False):\n    working_sample = np.copy(sample)\n\n    for i in range(iters):\n        v_s = vel(i, iters)\n        # apply doppler effect to sample\n        working_sample = ((v_m + v_o) / (v_m + v_s)) * working_sample  # doppler-effect\n        working_sample = f_act(working_sample)  # activation function\n\n        if conv:\n            working_sample = convolve2d(working_sample, kernel, mode='valid')  # convolution\n\n        if pool and i % 4 == 1:\n            working_sample = block_reduce(working_sample, (2, 2), np.mean, cval=0.5)\n\n    return working_sample"
        },
        {
            "cell_type": "markdown",
            "id": "6a247874",
            "metadata": {},
            "source": "###### Visualization\nChanging `iters` determines the size of the output (if conv and/or pooling are on)."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "f6f00fea",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "samples, labels = next(iter(loaders['train']))\nsample = samples[0][0]\n\n# vel_s is negative if moving towards observer\ndef v1(x, n):\n    return -(x + 1) / (n / 3)\ndef v2(x, n):\n    return x\ndef v3(x, n):\n    return 1.5\n\nv_o = 0  # positive if moving towards source\nv_m = 5.022  # small tail to avoid division errors.\nkernel = np.array([[2.5, 2.5],\n                   [2.5, 2.5]])"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "1d58ed0a",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "freq_sample (28, 28)\n[[ 4.03 -0.11 -4.12  0.11  1.39 -0.13  0.04  0.42 -0.33 -0.3   0.23 -0.12\n   0.04  0.07 -0.15  0.15  0.06 -0.1   0.03  0.   -0.11  0.04  0.12 -0.04\n  -0.02 -0.02 -0.01  0.09]\n [-0.35 -0.46 -0.22  1.26  0.91 -1.23 -0.33  0.31 -0.35  0.21  0.35 -0.03\n  -0.12 -0.07 -0.06  0.05  0.06 -0.09  0.06  0.03 -0.05  0.06 -0.03 -0.03\n   0.05 -0.04 -0.04  0.09]\n [-0.85 -0.14  1.17  0.24 -0.96 -0.08  0.59 -0.14 -0.28  0.23  0.11 -0.14\n  -0.04 -0.03 -0.    0.1   0.03 -0.07 -0.05  0.01  0.04  0.02 -0.02 -0.03\n   0.02  0.02 -0.01 -0.01]\n [ 1.07  0.74 -0.69 -1.91 -0.37  1.93  0.3  -0.87  0.13  0.09 -0.21 -0.01\n   0.13 -0.   -0.02  0.04 -0.03  0.05 -0.02 -0.04  0.02 -0.04  0.03  0.05\n  -0.05 -0.01  0.05 -0.03]\n [-2.26  0.22  1.59 -0.25  0.85  0.15 -1.48 -0.36  1.03  0.09 -0.56  0.43\n   0.12 -0.24  0.08 -0.17 -0.05  0.16  0.02 -0.04  0.03 -0.04 -0.02  0.09\n  -0.07 -0.03  0.07 -0.03]\n [ 0.39 -0.27  0.07  0.48 -0.57 -0.63 -0.07  1.03  0.55 -0.91 -0.26  0.32\n  -0.08 -0.09  0.18  0.07 -0.06  0.03 -0.1   0.    0.07 -0.05  0.03 -0.01\n  -0.03  0.06  0.03 -0.09]\n [-1.1   0.28  1.31 -0.49 -0.96  0.19  0.85  0.15 -0.75 -0.27  0.54  0.12\n  -0.35  0.12  0.2  -0.15 -0.11  0.01  0.04  0.06  0.05 -0.06 -0.1   0.03\n   0.08  0.02 -0.05 -0.05]\n [-1.23 -0.12  1.13  0.31 -0.25 -0.11  0.11 -0.45 -0.17  0.64  0.02 -0.39\n   0.09  0.28 -0.1  -0.26  0.06  0.1   0.04  0.   -0.1   0.02  0.06 -0.04\n  -0.02  0.02 -0.01  0.01]\n [ 0.76 -0.28 -0.26  0.39 -0.61 -0.21  0.16  0.22  0.39  0.09 -0.36 -0.49\n   0.26  0.27 -0.17  0.07  0.07 -0.04 -0.03 -0.04 -0.03  0.05  0.05 -0.06\n   0.01  0.03 -0.02 -0.01]\n [-1.19  0.21  0.95 -0.21 -0.12 -0.    0.25 -0.13 -0.34  0.08  0.04  0.15\n   0.07 -0.04  0.01 -0.06 -0.08 -0.04  0.07  0.04  0.09  0.   -0.17  0.02\n   0.11 -0.01 -0.05 -0.  ]\n [ 0.97 -0.18 -0.92  0.21  0.23  0.07  0.02 -0.21 -0.03  0.17  0.01 -0.04\n   0.05 -0.1  -0.06  0.05  0.07  0.07 -0.09 -0.03  0.05 -0.03 -0.03  0.04\n   0.02 -0.05  0.    0.04]\n [ 0.49 -0.06 -0.45  0.06  0.19 -0.02 -0.25  0.06  0.22  0.02 -0.   -0.12\n  -0.08 -0.03  0.02  0.2   0.02 -0.12 -0.03  0.01  0.03 -0.03  0.    0.09\n  -0.03 -0.08  0.03  0.04]\n [-0.08  0.15 -0.3  -0.11  0.55 -0.07 -0.02 -0.05 -0.23  0.01 -0.01  0.19\n   0.06 -0.07  0.07 -0.04 -0.16 -0.09  0.19  0.11 -0.15 -0.01  0.13 -0.05\n  -0.13  0.06  0.07 -0.04]\n [ 1.39 -0.18 -1.23  0.14  0.24  0.11 -0.05  0.01 -0.04 -0.05  0.23 -0.05\n  -0.12 -0.04 -0.03  0.01  0.05  0.17  0.02 -0.17 -0.12  0.11  0.09 -0.12\n   0.01  0.11 -0.01 -0.09]\n [-0.43  0.15  0.23 -0.16  0.22 -0.05 -0.14  0.09 -0.07 -0.08  0.15  0.07\n  -0.13 -0.   -0.03  0.02  0.16 -0.03 -0.17 -0.09  0.16  0.12 -0.13 -0.03\n   0.1  -0.02 -0.09  0.05]\n [ 0.18  0.06 -0.24 -0.09  0.11  0.02  0.06  0.05 -0.03 -0.12 -0.13  0.14\n   0.13 -0.03 -0.01 -0.05 -0.02 -0.05 -0.02  0.15  0.01 -0.11  0.    0.05\n  -0.01 -0.09  0.01  0.16]\n [ 0.05 -0.07  0.14 -0.03 -0.19  0.17 -0.15 -0.01  0.16 -0.06  0.12 -0.03\n  -0.11 -0.02 -0.02  0.03  0.01  0.07  0.07 -0.04 -0.12 -0.07  0.07  0.09\n   0.   -0.06  0.    0.02]\n [-0.57  0.19  0.37 -0.18  0.06 -0.06  0.08  0.03 -0.09 -0.04 -0.08  0.11\n   0.06 -0.01 -0.03  0.    0.09 -0.09 -0.09 -0.    0.06  0.08  0.03 -0.07\n  -0.08  0.08  0.01 -0.09]\n [ 0.26 -0.16 -0.09  0.21 -0.17 -0.07  0.02  0.06  0.11 -0.03 -0.08 -0.02\n   0.05 -0.04  0.03  0.02 -0.05 -0.01 -0.02  0.1   0.04 -0.08 -0.04 -0.01\n   0.01  0.02  0.05  0.  ]\n [-0.37 -0.03  0.38  0.08 -0.06 -0.09 -0.16  0.06  0.15 -0.03 -0.   -0.01\n  -0.06  0.01  0.03  0.03 -0.07 -0.    0.11 -0.03 -0.06 -0.04  0.01  0.09\n   0.   -0.03 -0.01 -0.04]\n [ 0.05  0.11 -0.16 -0.14  0.14  0.03  0.06 -0.04  0.   -0.01 -0.17  0.11\n   0.07 -0.08  0.09  0.04 -0.08 -0.05  0.01  0.01  0.    0.05  0.06 -0.06\n  -0.09  0.06  0.04 -0.07]\n [ 0.06 -0.14  0.08  0.12 -0.09  0.09 -0.2  -0.08  0.18  0.06  0.07 -0.06\n  -0.14 -0.05  0.13  0.02 -0.1   0.06  0.02  0.01  0.04 -0.06 -0.09  0.04\n   0.05 -0.05  0.04  0.05]\n [-0.1   0.07 -0.04  0.01  0.15 -0.17  0.03  0.12 -0.05 -0.04 -0.04 -0.03\n   0.03  0.15 -0.04 -0.1   0.04  0.01 -0.02 -0.04  0.04 -0.   -0.02  0.08\n   0.01 -0.05 -0.06  0.03]\n [ 0.13 -0.04 -0.05  0.03 -0.14  0.03  0.18 -0.06 -0.14  0.08  0.05 -0.06\n   0.02  0.02 -0.02 -0.05  0.04  0.06 -0.07 -0.02  0.05  0.03 -0.06 -0.05\n   0.08  0.02 -0.03 -0.01]\n [-0.17 -0.03  0.26 -0.   -0.2   0.11  0.06 -0.14 -0.07  0.14  0.12 -0.12\n  -0.03  0.03 -0.06  0.02  0.03  0.    0.03 -0.02 -0.04  0.04  0.   -0.04\n   0.02  0.01 -0.    0.03]\n [-0.04  0.11 -0.02 -0.12 -0.04 -0.02  0.23  0.   -0.12  0.02 -0.13 -0.04\n   0.19  0.1  -0.14 -0.02  0.06 -0.08  0.05  0.02 -0.1   0.03  0.12 -0.02\n  -0.07  0.03 -0.02 -0.01]\n [-0.22 -0.09  0.41  0.05 -0.35  0.11  0.07 -0.09 -0.03  0.08  0.1  -0.06\n  -0.03 -0.04 -0.01 -0.02  0.02  0.08 -0.02  0.01 -0.01 -0.03 -0.05 -0.02\n   0.08  0.02 -0.01 -0.05]\n [ 0.01  0.07 -0.07 -0.07  0.03 -0.04  0.14  0.04 -0.15 -0.04  0.04 -0.01\n   0.02  0.09 -0.07 -0.05  0.08 -0.01 -0.05 -0.04  0.02  0.06  0.04 -0.03\n  -0.06  0.04  0.01 -0.02]]\nresult (5, 5)\n[[3263416.75 2091845.81  997196.25  483549.61  189732.74]\n [1470795.37 1041257.5   714619.42  578437.35  251988.52]\n [ 889688.7   643202.75  495493.88  599368.04  288780.45]\n [ 731657.    534086.71  414866.35  407327.16  205479.61]\n [ 369854.54  281735.22  222063.23  170009.88   85913.05]]\n"
                }
            ],
            "source": "iters = 6\nf_act = relu  # relu, tanh, lrelu, rrelu, elu\nconv = True\npool = True\n\nfreq_sample = dct(dct(sample.numpy().T, norm='ortho').T, norm='ortho')  # decompose sample\nprint(f\"freq_sample {freq_sample.shape}\\n{np.round(freq_sample, 2)}\")\nresult = apply_dynamics(freq_sample, iters, f_act, v1, v_o, v_m, kernel, conv=conv, pool=pool)\nprint(f\"result {result.shape}\\n{np.round(result, 2)}\")"
        },
        {
            "cell_type": "markdown",
            "id": "bdc3ac5b",
            "metadata": {},
            "source": "###### Convert all data\nChanging `iters` determines the size of the output."
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "ed7453e3",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Begin reducing train\nReduced [30/600.0] train batches for 6 iterations\nReduced [60/600.0] train batches for 6 iterations\nReduced [90/600.0] train batches for 6 iterations\nReduced [120/600.0] train batches for 6 iterations\nReduced [150/600.0] train batches for 6 iterations\nReduced [180/600.0] train batches for 6 iterations\nReduced [210/600.0] train batches for 6 iterations\nReduced [240/600.0] train batches for 6 iterations\nReduced [270/600.0] train batches for 6 iterations\nReduced [300/600.0] train batches for 6 iterations\nReduced [330/600.0] train batches for 6 iterations\nReduced [360/600.0] train batches for 6 iterations\nReduced [390/600.0] train batches for 6 iterations\nReduced [420/600.0] train batches for 6 iterations\nReduced [450/600.0] train batches for 6 iterations\nReduced [480/600.0] train batches for 6 iterations\nReduced [510/600.0] train batches for 6 iterations\nReduced [540/600.0] train batches for 6 iterations\nReduced [570/600.0] train batches for 6 iterations\nReduced [600/600.0] train batches for 6 iterations\nBegin reducing test\nReduced [30/100.0] test batches for 6 iterations\nReduced [60/100.0] test batches for 6 iterations\nReduced [90/100.0] test batches for 6 iterations\n(70000, 3)\n"
                }
            ],
            "source": "# iters = 18\n# f_act = relu\n# conv = False\n# pool = False\n\ndf_results = pd.DataFrame(columns=['data', 'label', 'train'])\nfor dset in [\"train\", \"test\"]:\n    batch_size = 100\n    batches = data_len[dset] / batch_size\n    print(f\"Begin reducing {dset}\")\n    for b, (images, labels) in enumerate(loaders[dset]):\n        if b == batches:\n            break\n        for i in range(batch_size):\n            freq_sample = dct(dct(images[i].numpy()[0].T, norm='ortho').T, norm='ortho')  # decompose sample\n            result = apply_dynamics(freq_sample, iters, f_act, v1, v_o, v_m, kernel, conv=conv, pool=pool)\n            result_str = np.array2string(result, separator=',')\n            df_results = pd.concat([df_results, pd.DataFrame([[result_str, labels[i].numpy(), dset == \"train\"]], columns=df_results.columns)], ignore_index=True)\n\n        if (b + 1) % 30 == 0:\n            print('Reduced [{}/{}] {} batches for {} iterations'\n                  .format(b + 1, batches, dset, iters))\n\nprint(df_results.shape)\ndf_results.to_csv(f'freq_RedData/freq_RedData_{iters}i_conv{\"_pool\" if pool else \"\"}_{f_act.__name__}_v1.csv', index=False)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "toc": {
            "base_numbering": 1,
            "nav_menu": {},
            "number_sections": true,
            "sideBar": true,
            "skip_h1_title": false,
            "title_cell": "Table of Contents",
            "title_sidebar": "Contents",
            "toc_cell": false,
            "toc_position": {},
            "toc_section_display": true,
            "toc_window_display": false
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}